import streamlit as st
import requests
import time
import re
from datetime import date, datetime
import json
import pandas as pd
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go

# æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆjanomeé–¢é€£ï¼‰
try:
    from janome.tokenizer import Tokenizer
    JANOME_AVAILABLE = True
except ImportError:
    JANOME_AVAILABLE = False
    st.warning("janomeãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å½¢æ…‹ç´ è§£ææ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")

try:
    from wordcloud import WordCloud
    import matplotlib.pyplot as plt
    import matplotlib.font_manager as fm
    import numpy as np
    WORDCLOUD_AVAILABLE = True
except ImportError:
    WORDCLOUD_AVAILABLE = False

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å›½ä¼šè­°äº‹éŒ²æ¤œç´¢ã‚¢ãƒ—ãƒª",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f4e79;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .sub-header {
        font-size: 1.5rem;
        color: #2e6da4;
        margin-bottom: 1rem;
    }
    .highlight-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        margin: 20px 0;
    }
    .metric-card {
        background: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #1f4e79;
    }
    .speech-card {
        background: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
        border-left: 4px solid #17a2b8;
    }
</style>
""", unsafe_allow_html=True)

# APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
API_URL = "https://kokkai.ndl.go.jp/api/speech"

class KokkaiSearchApp:
    def __init__(self):
        if 'search_history' not in st.session_state:
            st.session_state.search_history = []
        if 'search_results' not in st.session_state:
            st.session_state.search_results = None
        if 'analytics_data' not in st.session_state:
            st.session_state.analytics_data = {}

        # janomeåˆæœŸåŒ–ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
        if JANOME_AVAILABLE:
            self.tokenizer = Tokenizer()

            # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼ˆé™¤å¤–ã™ã‚‹å˜èªï¼‰
            self.stop_words = {
                'ã™ã‚‹', 'ã‚ã‚‹', 'ã„ã‚‹', 'ãªã‚‹', 'ã‚Œã‚‹', 'ã“ã®', 'ãã®', 'ã‚ã®', 'ã¨ã„ã†', 'ã¨ã„ã£ãŸ',
                'ã¨ã—ã¦', 'ã«ã¤ã„ã¦', 'ã«ãŠã„ã¦', 'ã«å¯¾ã—ã¦', 'ã¨ã„ã†ãµã†ã«', 'ã ã¨', 'ã§ã‚ã‚‹', 'ã§ã™',
                'ã¾ã™', 'ã§ã', 'ã‚ˆã†', 'ã‚‚ã®', 'ã“ã¨', 'å ´åˆ', 'ä¸­', 'ç§', 'æˆ‘ã€…', 'çš†ã•ã‚“', 'çš†æ§˜',
                'ä»Š', 'ç¾åœ¨', 'ä»Šå›', 'ä»Šåº¦', 'å…ˆã»ã©', 'å…ˆç¨‹', 'æœ¬æ—¥', 'ä»Šæ—¥', 'æ˜¨æ—¥', 'æ˜æ—¥',
                'ã¯ã„', 'ã„ãˆ', 'ãˆãˆ', 'ã†ã‚“', 'ãã†', 'ã„ã‚„', 'ã¾ã‚', 'ã¡ã‚‡ã£ã¨', 'ã‚„ã¯ã‚Š', 'ã‚„ã£ã±ã‚Š',
                'å§”å“¡', 'å¤§è‡£', 'è­°å“¡', 'å…ˆç”Ÿ', 'ç·ç†', 'å‰¯', 'ä¼šé•·', 'ç†äº‹', 'é•·', 'éƒ¨é•·', 'èª²é•·',
                'æ™‚é–“', 'åˆ†', 'ç§’', 'å¹´', 'æœˆ', 'æ—¥', 'é€±', 'å›', 'åº¦', 'ç•ª', 'å·', 'ç¬¬', 'ç« ', 'æ¡',
                'æ€ã†', 'è€ƒãˆã‚‹', 'æ„Ÿã˜ã‚‹', 'è¦‹ã‚‹', 'èã', 'è¨€ã†', 'è©±ã™', 'è¿°ã¹ã‚‹', 'ç”³ã—ä¸Šã’ã‚‹'
            }
        else:
            self.tokenizer = None
            self.stop_words = set()

    def highlight_text(self, text, keywords_str):
        """ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ"""
        if not keywords_str or not text:
            return text

        keywords = keywords_str.split()
        highlighted_text = text

        for keyword in keywords:
            highlighted_text = re.sub(
                re.escape(keyword),
                lambda m: f'<span style="background-color: #fff3cd; padding: 2px 4px; border-radius: 3px; font-weight: bold;">{m.group(0)}</span>',
                highlighted_text,
                flags=re.IGNORECASE
            )
        return highlighted_text

    def search_speeches(self, params):
        """å›½ä¼šä¼šè­°éŒ²APIæ¤œç´¢"""
        try:
            api_params = {
                "maximumRecords": 30,
                "recordPacking": "json"
            }
            api_params.update(params)

            response = requests.get(API_URL, params=api_params, timeout=15.0)
            response.raise_for_status()

            if response.text:
                return response.json()
            return None
        except requests.exceptions.RequestException as e:
            st.error(f"APIã¸ã®æ¥ç¶šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None
        except ValueError:
            st.error("APIã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ãªå½¢å¼ã§ã™ã€‚")
            return None

    def extract_keywords(self, text, min_length=2, top_n=50):
        """janomeã‚’ä½¿ã£ã¦å½¢æ…‹ç´ è§£æã—ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        if not JANOME_AVAILABLE or not text:
            return {}

        keywords = []

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’å½¢æ…‹ç´ è§£æ
        tokens = self.tokenizer.tokenize(text)

        for token in tokens:
            # å“è©æƒ…å ±ã‚’å–å¾—
            features = token.part_of_speech.split(',')
            word = token.surface.strip()

            # æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if (len(word) >= min_length and  # æŒ‡å®šæ–‡å­—æ•°ä»¥ä¸Š
                word not in self.stop_words and  # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é™¤å¤–
                not word.isdigit() and  # æ•°å­—ã®ã¿é™¤å¤–
                features[0] in ['åè©', 'å‹•è©', 'å½¢å®¹è©'] and  # å“è©ãƒ•ã‚£ãƒ«ã‚¿
                features[1] not in ['ä»£åè©', 'æ•°', 'æ¥å°¾'] and  # ç´°åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿
                not re.match(r'^[ã-ã‚“]+$', word)):  # ã²ã‚‰ãŒãªã®ã¿é™¤å¤–

                # å‹•è©ã®å ´åˆã¯åŸå½¢ã«å¤‰æ›
                if features[0] == 'å‹•è©' and len(features) >= 7 and features[6] != '*':
                    keywords.append(features[6])
                else:
                    keywords.append(word)

        # å˜èªã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        keyword_counts = Counter(keywords)
        return dict(keyword_counts.most_common(top_n))

    def analyze_meeting_keywords(self, data):
        """ä¼šè­°åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ"""
        if not data or "speechRecord" not in data:
            return {}

        records = data["speechRecord"]
        meeting_analysis = {}

        # ä¼šè­°åˆ¥ã«ç™ºè¨€ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        meeting_groups = {}
        for record in records:
            meeting_name = record.get('nameOfMeeting', 'ä¸æ˜')
            if meeting_name not in meeting_groups:
                meeting_groups[meeting_name] = []
            meeting_groups[meeting_name].append(record)

        # å„ä¼šè­°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        for meeting_name, meeting_records in meeting_groups.items():
            # å…¨ç™ºè¨€ã‚’çµåˆ
            all_speeches = ' '.join([record.get('speech', '') for record in meeting_records])

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
            keywords = self.extract_keywords(all_speeches)

            # ç™ºè¨€è€…ãƒªã‚¹ãƒˆ
            speakers = list(set([record.get('speaker', 'ä¸æ˜') for record in meeting_records]))

            meeting_analysis[meeting_name] = {
                'keywords': keywords,
                'speakers': speakers,
                'total_speeches': len(meeting_records),
                'total_characters': len(all_speeches),
                'speeches': meeting_records
            }

        return meeting_analysis

    def create_wordcloud(self, keywords):
        """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”Ÿæˆ"""
        if not WORDCLOUD_AVAILABLE or not keywords:
            return None

        try:
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
            font_path = None
            # ã‚·ã‚¹ãƒ†ãƒ ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¢ã™
            fonts = fm.findSystemFonts()
            for font in fonts:
                if any(jp_font in font.lower() for jp_font in ['noto', 'hiragino', 'yu', 'meiryo', 'msgothic']):
                    font_path = font
                    break

            wordcloud = WordCloud(
                width=800,
                height=400,
                background_color='white',
                font_path=font_path,
                colormap='viridis',
                max_words=100,
                relative_scaling=0.5,
                random_state=42
            ).generate_from_frequencies(keywords)

            return wordcloud
        except Exception as e:
            st.warning(f"ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None

    def analyze_search_results(self, data):
        """æ¤œç´¢çµæœã®åˆ†æ"""
        if not data or "speechRecord" not in data:
            return {}

        records = data["speechRecord"]

        # ç™ºè¨€è€…ã®åˆ†æ
        speakers = [record.get('speaker', 'ä¸æ˜') for record in records]
        speaker_counts = Counter(speakers)

        # ä¼šè­°ã®åˆ†æ
        meetings = [record.get('nameOfMeeting', 'ä¸æ˜') for record in records]
        meeting_counts = Counter(meetings)

        # æ—¥ä»˜ã®åˆ†æ
        dates = []
        for record in records:
            date_str = record.get('date', '')
            if date_str:
                try:
                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                    dates.append(date_obj)
                except:
                    pass

        # ç™ºè¨€ã®é•·ã•åˆ†æ
        speech_lengths = [len(record.get('speech', '')) for record in records]

        return {
            'total_records': len(records),
            'speaker_counts': dict(speaker_counts.most_common(10)),
            'meeting_counts': dict(meeting_counts.most_common(10)),
            'dates': dates,
            'speech_lengths': speech_lengths,
            'avg_speech_length': sum(speech_lengths) / len(speech_lengths) if speech_lengths else 0
        }

    def create_visualizations(self, analytics):
        """ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–"""
        if not analytics:
            return

        col1, col2 = st.columns(2)

        with col1:
            if analytics.get('speaker_counts'):
                st.subheader("ğŸ“Š ç™ºè¨€è€…åˆ¥ä»¶æ•°")
                speakers_df = pd.DataFrame(
                    list(analytics['speaker_counts'].items()),
                    columns=['ç™ºè¨€è€…', 'ä»¶æ•°']
                )
                fig = px.bar(speakers_df, x='ä»¶æ•°', y='ç™ºè¨€è€…', orientation='h',
                           color='ä»¶æ•°', color_continuous_scale='Blues')
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)

        with col2:
            if analytics.get('meeting_counts'):
                st.subheader("ğŸ›ï¸ ä¼šè­°åˆ¥ä»¶æ•°")
                meetings_df = pd.DataFrame(
                    list(analytics['meeting_counts'].items()),
                    columns=['ä¼šè­°å', 'ä»¶æ•°']
                )
                fig = px.pie(meetings_df, values='ä»¶æ•°', names='ä¼šè­°å',
                           color_discrete_sequence=px.colors.qualitative.Set3)
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)

        # æ™‚ç³»åˆ—åˆ†æ
        if analytics.get('dates'):
            st.subheader("ğŸ“… æ™‚ç³»åˆ—åˆ†æ")
            dates_df = pd.DataFrame({'æ—¥ä»˜': analytics['dates']})
            dates_df['å¹´æœˆ'] = dates_df['æ—¥ä»˜'].dt.to_period('M')
            monthly_counts = dates_df.groupby('å¹´æœˆ').size().reset_index(name='ä»¶æ•°')
            monthly_counts['å¹´æœˆ'] = monthly_counts['å¹´æœˆ'].astype(str)

            fig = px.line(monthly_counts, x='å¹´æœˆ', y='ä»¶æ•°',
                         title='æœˆåˆ¥ç™ºè¨€ä»¶æ•°ã®æ¨ç§»',
                         markers=True)
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)

    def export_results(self, data, search_params):
        """æ¤œç´¢çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if not data or "speechRecord" not in data:
            return None

        records = data["speechRecord"]
        export_data = []

        for record in records:
            export_data.append({
                'ç™ºè¨€æ—¥': record.get('date', ''),
                'ç™ºè¨€è€…': record.get('speaker', ''),
                'ä¼šè­°å': record.get('nameOfMeeting', ''),
                'é™¢å': record.get('nameOfHouse', ''),
                'ç™ºè¨€å†…å®¹': record.get('speech', '')[:500] + '...' if len(record.get('speech', '')) > 500 else record.get('speech', ''),
                'URL': record.get('speechURL', '')
            })

        df = pd.DataFrame(export_data)
        return df

    def main(self):
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        st.markdown('<h1 class="main-header">ğŸ›ï¸ å›½ä¼šè­°äº‹éŒ²æ¤œç´¢ãƒ»åˆ†æã‚¢ãƒ—ãƒª</h1>', unsafe_allow_html=True)

        # ã‚µã‚¤ãƒ‰ãƒãƒ¼
        with st.sidebar:
            st.markdown("### ğŸ” æ¤œç´¢ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
            page_options = ["ğŸ” æ¤œç´¢", "ğŸ“Š åˆ†æ", "ğŸ“š æ¤œç´¢å±¥æ­´", "â„¹ï¸ ä½¿ã„æ–¹"]

            # janomeåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚’è¿½åŠ 
            if JANOME_AVAILABLE:
                page_options.insert(2, "ğŸ›ï¸ ä¼šè­°åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ")

            page = st.selectbox("ãƒšãƒ¼ã‚¸ã‚’é¸æŠ", page_options)

        if page == "ğŸ” æ¤œç´¢":
            self.search_page()
        elif page == "ğŸ“Š åˆ†æ":
            self.analysis_page()
        elif page == "ğŸ›ï¸ ä¼šè­°åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ" and JANOME_AVAILABLE:
            self.meeting_analysis_page()
        elif page == "ğŸ“š æ¤œç´¢å±¥æ­´":
            self.history_page()
        else:
            self.help_page()

    def search_page(self):
        st.markdown('<h2 class="sub-header">ğŸ” å›½ä¼šè­°äº‹éŒ²æ¤œç´¢</h2>', unsafe_allow_html=True)

        # æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form("search_form"):
            keyword = st.text_input("ğŸ” æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆANDæ¤œç´¢ï¼‰",
                                  placeholder="ä¾‹ï¼šãƒ‡ã‚¸ã‚¿ãƒ«æ”¹é© è¦åˆ¶ç·©å’Œ",
                                  help="è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›")

            col1, col2, col3 = st.columns(3)
            with col1:
                speaker = st.text_input("ğŸ‘¤ ç™ºè¨€è€…å", placeholder="ä¾‹ï¼šå²¸ç”°æ–‡é›„")
            with col2:
                name_of_meeting = st.text_input("ğŸ›ï¸ ä¼šè­°å", placeholder="ä¾‹ï¼šäºˆç®—å§”å“¡ä¼š")
            with col3:
                name_of_house = st.selectbox("ğŸ¢ é™¢å", ("æŒ‡å®šã—ãªã„", "è¡†è­°é™¢", "å‚è­°é™¢", "ä¸¡é™¢"))

            col4, col5 = st.columns(2)
            with col4:
                from_date = st.date_input("ğŸ“… æ¤œç´¢æœŸé–“ï¼ˆé–‹å§‹æ—¥ï¼‰", value=None)
            with col5:
                until_date = st.date_input("ğŸ“… æ¤œç´¢æœŸé–“ï¼ˆçµ‚äº†æ—¥ï¼‰", value=None)

            search_button = st.form_submit_button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", type="primary")

        if search_button:
            # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ§‹ç¯‰
            search_params = {}

            if keyword:
                search_params["any"] = keyword
            if speaker:
                search_params["speaker"] = speaker
            if name_of_meeting:
                search_params["nameOfMeeting"] = name_of_meeting
            if name_of_house != "æŒ‡å®šã—ãªã„":
                search_params["nameOfHouse"] = name_of_house
            if from_date:
                search_params["from"] = from_date.strftime('%Y-%m-%d')
            if until_date:
                search_params["until"] = until_date.strftime('%Y-%m-%d')

            if search_params:
                with st.spinner("ğŸ” æ¤œç´¢ä¸­ã§ã™..."):
                    time.sleep(1)
                    data = self.search_speeches(search_params)

                    if data and "speechRecord" in data and data["speechRecord"]:
                        st.session_state.search_results = data
                        st.session_state.analytics_data = self.analyze_search_results(data)

                        # janomeåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚’å®Ÿè¡Œ
                        if JANOME_AVAILABLE:
                            st.session_state.meeting_analysis = self.analyze_meeting_keywords(data)

                        # æ¤œç´¢å±¥æ­´ã«è¿½åŠ 
                        search_history_item = {
                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                            'params': search_params,
                            'results_count': data['numberOfRecords']
                        }
                        st.session_state.search_history.insert(0, search_history_item)
                        if len(st.session_state.search_history) > 10:
                            st.session_state.search_history.pop()

                        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                        st.success(f"âœ… æ¤œç´¢çµæœãŒ {data['numberOfRecords']} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ï¼ˆæœ€å¤§30ä»¶è¡¨ç¤ºï¼‰")

                        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
                        export_df = self.export_results(data, search_params)
                        if export_df is not None:
                            csv = export_df.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                label="ğŸ“„ æ¤œç´¢çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=csv,
                                file_name=f"kokkai_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv"
                            )

                        # æ¤œç´¢çµæœè¡¨ç¤º
                        for i, record in enumerate(data["speechRecord"]):
                            with st.expander(f"ğŸ“ {record['speaker']}ï¼ˆ{record['nameOfMeeting']}ï¼‰- {record['date']}"):
                                col1, col2 = st.columns([3, 1])

                                with col1:
                                    st.markdown(f"**ğŸ“… ç™ºè¨€æ—¥:** {record['date']}")
                                    st.markdown(f"**ğŸ‘¤ ç™ºè¨€è€…:** {record['speaker']}")
                                    st.markdown(f"**ğŸ›ï¸ ä¼šè­°:** {record['nameOfMeeting']}")
                                    st.markdown(f"**ğŸ¢ é™¢:** {record.get('nameOfHouse', 'ä¸æ˜')}")

                                with col2:
                                    speech_length = len(record['speech'])
                                    st.metric("æ–‡å­—æ•°", f"{speech_length:,}")

                                st.markdown("---")

                                # ç™ºè¨€å†…å®¹ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º
                                speech_text = record['speech']
                                highlighted_speech = self.highlight_text(speech_text, keyword)

                                st.markdown(
                                    f'<div class="speech-card" style="height: 300px; overflow-y: auto;">{highlighted_speech}</div>',
                                    unsafe_allow_html=True
                                )

                                st.markdown(f"ğŸ”— [ç™ºè¨€ã®å…¨æ–‡ã¨å‘¨è¾ºè­°äº‹ã‚’èª­ã‚€]({record['speechURL']})")
                    else:
                        st.warning("âš ï¸ æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’å¤‰ãˆã¦è©¦ã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error("âŒ æ¤œç´¢æ¡ä»¶ã‚’ä½•ã‹ä¸€ã¤ä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    def meeting_analysis_page(self):
        st.markdown('<h2 class="sub-header">ğŸ›ï¸ ä¼šè­°åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ</h2>', unsafe_allow_html=True)

        if not JANOME_AVAILABLE:
            st.error("âŒ ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ janome ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚")
            st.code("pip install janome")
            return

        if 'meeting_analysis' not in st.session_state or not st.session_state.meeting_analysis:
            st.info("ğŸ” åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return

        meeting_analysis = st.session_state.meeting_analysis

        # ä¼šè­°é¸æŠ
        selected_meeting = st.selectbox(
            "ğŸ“‹ åˆ†æã™ã‚‹ä¼šè­°ã‚’é¸æŠã—ã¦ãã ã•ã„",
            list(meeting_analysis.keys()),
            help="æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹ä¼šè­°ã‹ã‚‰é¸æŠ"
        )

        if selected_meeting:
            meeting_data = meeting_analysis[selected_meeting]

            # ä¼šè­°ã®åŸºæœ¬æƒ…å ±
            st.markdown("### ğŸ“Š ä¼šè­°åŸºæœ¬æƒ…å ±")
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("ç™ºè¨€æ•°", f"{meeting_data['total_speeches']}ä»¶")
            with col2:
                st.metric("ç™ºè¨€è€…æ•°", f"{len(meeting_data['speakers'])}äºº")
            with col3:
                st.metric("ç·æ–‡å­—æ•°", f"{meeting_data['total_characters']:,}å­—")
            with col4:
                avg_chars = meeting_data['total_characters'] // meeting_data['total_speeches']
                st.metric("å¹³å‡æ–‡å­—æ•°", f"{avg_chars:,}å­—/ç™ºè¨€")

            # ç™ºè¨€è€…ä¸€è¦§
            st.markdown("### ğŸ‘¥ ç™ºè¨€è€…ä¸€è¦§")
            speakers_text = "ã€".join(meeting_data['speakers'])
            st.write(speakers_text)

            st.markdown("---")

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
            if meeting_data['keywords']:
                st.markdown("### ğŸ”¤ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ")

                # ã‚¿ãƒ–ã§è¡¨ç¤ºæ–¹æ³•ã‚’åˆ‡ã‚Šæ›¿ãˆ
                tab1, tab2, tab3 = st.tabs(["ğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "â˜ï¸ ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰", "ğŸ“ˆ è©³ç´°åˆ†æ"])

                with tab1:
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°
                    col1, col2 = st.columns([2, 1])

                    with col1:
                        keywords_df = pd.DataFrame(
                            list(meeting_data['keywords'].items())[:20],
                            columns=['ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'å‡ºç¾å›æ•°']
                        )

                        fig = px.bar(
                            keywords_df,
                            x='å‡ºç¾å›æ•°',
                            y='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰',
                            orientation='h',
                            title=f"{selected_meeting} - ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ Top20",
                            color='å‡ºç¾å›æ•°',
                            color_continuous_scale='Viridis'
                        )
                        fig.update_layout(height=600)
                        st.plotly_chart(fig, use_container_width=True)

                    with col2:
                        st.markdown("#### ğŸ“‹ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§")
                        for i, (keyword, count) in enumerate(list(meeting_data['keywords'].items())[:15], 1):
                            st.write(f"{i:2d}. **{keyword}** ({count}å›)")

                with tab2:
                    # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰
                    st.markdown("#### â˜ï¸ ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰")
                    if WORDCLOUD_AVAILABLE:
                        wordcloud = self.create_wordcloud(meeting_data['keywords'])

                        if wordcloud:
                            fig, ax = plt.subplots(figsize=(12, 6))
                            ax.imshow(wordcloud, interpolation='bilinear')
                            ax.axis('off')
                            st.pyplot(fig)
                            plt.close()
                        else:
                            st.warning("ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        st.warning("ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ wordcloud ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚")
                        st.code("pip install wordcloud")

                with tab3:
                    # è©³ç´°åˆ†æ
                    st.markdown("#### ğŸ“ˆ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è©³ç´°åˆ†æ")

                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é•·åˆ¥åˆ†å¸ƒ
                    keyword_lengths = [len(k) for k in meeting_data['keywords'].keys()]
                    length_counts = Counter(keyword_lengths)

                    col1, col2 = st.columns(2)

                    with col1:
                        length_df = pd.DataFrame(
                            list(length_counts.items()),
                            columns=['æ–‡å­—æ•°', 'å˜èªæ•°']
                        ).sort_values('æ–‡å­—æ•°')

                        fig = px.bar(
                            length_df,
                            x='æ–‡å­—æ•°',
                            y='å˜èªæ•°',
                            title="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ–‡å­—æ•°åˆ†å¸ƒ"
                        )
                        st.plotly_chart(fig, use_container_width=True)

                    with col2:
                        # å‡ºç¾é »åº¦åˆ†å¸ƒ
                        freq_counts = Counter(meeting_data['keywords'].values())
                        freq_df = pd.DataFrame(
                            list(freq_counts.items()),
                            columns=['å‡ºç¾å›æ•°', 'å˜èªæ•°']
                        ).sort_values('å‡ºç¾å›æ•°')

                        fig = px.bar(
                            freq_df,
                            x='å‡ºç¾å›æ•°',
                            y='å˜èªæ•°',
                            title="å‡ºç¾é »åº¦åˆ†å¸ƒ"
                        )
                        st.plotly_chart(fig, use_container_width=True)

                    # çµ±è¨ˆæƒ…å ±
                    st.markdown("#### ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼")
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        total_keywords = len(meeting_data['keywords'])
                        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°", f"{total_keywords}")

                    with col2:
                        total_occurrences = sum(meeting_data['keywords'].values())
                        st.metric("ç·å‡ºç¾å›æ•°", f"{total_occurrences}")

                    with col3:
                        avg_occurrence = total_occurrences / total_keywords if total_keywords > 0 else 0
                        st.metric("å¹³å‡å‡ºç¾å›æ•°", f"{avg_occurrence:.1f}")

                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢æ©Ÿèƒ½
                st.markdown("---")
                st.markdown("### ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢")
                search_keyword = st.text_input("ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢", placeholder="ä¾‹ï¼šãƒ‡ã‚¸ã‚¿ãƒ«")

                if search_keyword:
                    matching_keywords = {
                        k: v for k, v in meeting_data['keywords'].items()
                        if search_keyword.lower() in k.lower()
                    }

                    if matching_keywords:
                        st.success(f"'{search_keyword}' ã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒ {len(matching_keywords)} å€‹è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")

                        for keyword, count in sorted(matching_keywords.items(), key=lambda x: x[1], reverse=True):
                            st.write(f"â€¢ **{keyword}**: {count}å›")
                    else:
                        st.warning(f"'{search_keyword}' ã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

            else:
                st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    def analysis_page(self):
        st.markdown('<h2 class="sub-header">ğŸ“Š æ¤œç´¢çµæœåˆ†æ</h2>', unsafe_allow_html=True)

        if st.session_state.analytics_data:
            analytics = st.session_state.analytics_data

            # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.markdown(
                    f'<div class="metric-card"><h3>ğŸ“Š ç·ä»¶æ•°</h3><h2>{analytics["total_records"]}</h2></div>',
                    unsafe_allow_html=True
                )

            with col2:
                avg_length = int(analytics.get("avg_speech_length", 0))
                st.markdown(
                    f'<div class="metric-card"><h3>ğŸ“ å¹³å‡æ–‡å­—æ•°</h3><h2>{avg_length:,}</h2></div>',
                    unsafe_allow_html=True
                )

            with col3:
                unique_speakers = len(analytics.get("speaker_counts", {}))
                st.markdown(
                    f'<div class="metric-card"><h3>ğŸ‘¥ ç™ºè¨€è€…æ•°</h3><h2>{unique_speakers}</h2></div>',
                    unsafe_allow_html=True
                )

            with col4:
                unique_meetings = len(analytics.get("meeting_counts", {}))
                st.markdown(
                    f'<div class="metric-card"><h3>ğŸ›ï¸ ä¼šè­°æ•°</h3><h2>{unique_meetings}</h2></div>',
                    unsafe_allow_html=True
                )

            st.markdown("---")

            # å¯è¦–åŒ–
            self.create_visualizations(analytics)

        else:
            st.info("ğŸ“Š åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

    def history_page(self):
        st.markdown('<h2 class="sub-header">ğŸ“š æ¤œç´¢å±¥æ­´</h2>', unsafe_allow_html=True)

        if st.session_state.search_history:
            for i, item in enumerate(st.session_state.search_history):
                with st.expander(f"ğŸ• {item['timestamp']} - {item['results_count']}ä»¶"):
                    st.json(item['params'])
        else:
            st.info("ğŸ“š æ¤œç´¢å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    def help_page(self):
        st.markdown('<h2 class="sub-header">â„¹ï¸ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰</h2>', unsafe_allow_html=True)

        st.markdown("""
        ### ğŸ” æ¤œç´¢æ©Ÿèƒ½
        - **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢**: ç™ºè¨€å†…å®¹ã‹ã‚‰è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ AND æ¤œç´¢
        - **ç™ºè¨€è€…æ¤œç´¢**: ç‰¹å®šã®æ”¿æ²»å®¶åã§æ¤œç´¢
        - **ä¼šè­°åæ¤œç´¢**: å§”å“¡ä¼šåãªã©ã§æ¤œç´¢
        - **æœŸé–“æŒ‡å®š**: æ—¥ä»˜ç¯„å›²ã§ã®çµã‚Šè¾¼ã¿
        - **é™¢åˆ¥æ¤œç´¢**: è¡†è­°é™¢ãƒ»å‚è­°é™¢ã§ã®çµã‚Šè¾¼ã¿

        ### ğŸ›ï¸ ä¼šè­°åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†ææ©Ÿèƒ½
        - **å½¢æ…‹ç´ è§£æ**: janomeãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã‚ˆã‚‹æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆè§£æ
        - **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º**: åè©ãƒ»å‹•è©ãƒ»å½¢å®¹è©ã‹ã‚‰é‡è¦èªå¥ã‚’æŠ½å‡º
        - **ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰**: è¦–è¦šçš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¡¨ç¤º
        - **è©³ç´°çµ±è¨ˆ**: æ–‡å­—æ•°åˆ†å¸ƒã€å‡ºç¾é »åº¦åˆ†æ
        - **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢**: ç‰¹å®šèªå¥ã®é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢

        ### ğŸ“Š åˆ†ææ©Ÿèƒ½
        - **çµ±è¨ˆã‚µãƒãƒªãƒ¼**: æ¤œç´¢çµæœã®åŸºæœ¬çµ±è¨ˆ
        - **ç™ºè¨€è€…åˆ†æ**: ç™ºè¨€è€…åˆ¥ã®ä»¶æ•°ã‚°ãƒ©ãƒ•
        - **ä¼šè­°åˆ†æ**: ä¼šè­°åˆ¥ã®åˆ†é¡å††ã‚°ãƒ©ãƒ•
        - **æ™‚ç³»åˆ—åˆ†æ**: æœˆåˆ¥ç™ºè¨€ä»¶æ•°ã®æ¨ç§»

        ### ğŸ’¾ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
        - **CSVå‡ºåŠ›**: æ¤œç´¢çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        - **æ¤œç´¢å±¥æ­´**: éå»ã®æ¤œç´¢æ¡ä»¶ã‚’ä¿å­˜ãƒ»ç¢ºèª

        ### ğŸ¨ ç‰¹å¾´
        - **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚¤ãƒ©ã‚¤ãƒˆ**: æ¤œç´¢èªå¥ã‚’çµæœå†…ã§å¼·èª¿è¡¨ç¤º
        - **ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³**: ç¾ã—ã„UI/UX
        - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ**: æ¤œç´¢ã¨åŒæ™‚ã«ãƒ‡ãƒ¼ã‚¿åˆ†æ

        ### ğŸ“¦ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
        ```bash
        pip install streamlit requests pandas plotly janome wordcloud matplotlib numpy
        ```
        """)

        st.markdown("---")
        st.info("""
        **ã€ã”åˆ©ç”¨ä¸Šã®æ³¨æ„ã€‘**
        - ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å›½ç«‹å›½ä¼šå›³æ›¸é¤¨ã®[å›½ä¼šä¼šè­°éŒ²æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ æ¤œç´¢ç”¨API](https://kokkai.ndl.go.jp/api.html)ã‚’åˆ©ç”¨ã—ã¦ã„ã¾ã™ã€‚
        - ã‚µãƒ¼ãƒãƒ¼ã«è² è·ã‚’ã‹ã‘ãªã„ã‚ˆã†ã€é€£ç¶šã§ã®æ¤œç´¢ã¯ãŠæ§ãˆãã ã•ã„ã€‚
        - å›½ä¼šè­°äº‹éŒ²ã«ãŠã‘ã‚‹å„ç™ºè¨€ã®è‘—ä½œæ¨©ã¯ã€åŸå‰‡ã¨ã—ã¦ãã‚Œãã‚Œã®ç™ºè¨€è€…ã«å¸°å±ã—ã¾ã™ã€‚
        - å½¢æ…‹ç´ è§£ææ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ janome ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚
        - ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ wordcloud ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚
        """)

# ã‚¢ãƒ—ãƒªå®Ÿè¡Œ
if __name__ == "__main__":
    app = KokkaiSearchApp()
    app.main()
